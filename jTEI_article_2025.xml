<?xml version="1.0" encoding="UTF-8"?>
<?xml-model href="http://www.tei-c.org/release/xml/tei/custom/schema/relaxng/tei_jtei.rng" type="application/xml" schematypens="http://relaxng.org/ns/structure/1.0"?>
<?xml-model href="http://www.tei-c.org/release/xml/tei/custom/schema/relaxng/tei_jtei.rng" type="application/xml" schematypens="http://purl.oclc.org/dsdl/schematron"?>
<TEI xmlns="http://www.tei-c.org/ns/1.0" rend="jTEI">
  <teiHeader>
    <fileDesc>
      <titleStmt>
        <title type="main">Preserving a Listserv Archive in TEI: The Case of TEI-L</title>
        <author xml:id="sb">
          <name>
            <forename>Syd</forename>
            <surname>Bauman</surname>
          </name>
          <affiliation>
            <roleName>Senior XML Programmer/Analyst</roleName>
            <affiliation>Northeastern University</affiliation>
          </affiliation>
          <affiliation>
            <roleName>member</roleName>
            <orgName>TEI Technical Council</orgName>
          </affiliation>
          <email>s.bauman@northeastern.edu</email>
        </author>
        <author xml:id="ebb">
          <name>
            <forename>Elisa</forename>
            <surname>Beshero-Bondar</surname>
          </name>
          <affiliation>
            <roleName>Professor of Digital Humanities</roleName>
            <roleName>Director of the Digital Humanities Lab</roleName>
            <orgName>Penn State Erie, The Behrend College</orgName>
          </affiliation>
          <affiliation>
            <roleName>chair</roleName>
            <orgName>TEI Technical Council</orgName>
          </affiliation>
          <email>eeb4@psu.edu</email>
        </author>
      </titleStmt>
      <publicationStmt>
        <publisher>TEI Consortium</publisher>
        <date>due 2025-03-07</date>
        <availability>
          <licence target="https://creativecommons.org/licenses/by/4.0/">
            <p>For this publication a Creative Commons Attribution 4.0 International
            license has been granted by the author(s) who retain full copyright.</p>
          </licence>
        </availability>
      </publicationStmt>
      <sourceDesc>
        <p>No source, born digital; based in large part on our <ref
        target="https://bit.ly/listserv2tei">presentation</ref> at the
        TEI Conference and Members’ Meeting 2024 in Buenos Aires.</p>
      </sourceDesc>
    </fileDesc>
    <encodingDesc>
      <projectDesc>
        <p>OpenEdition Journals -centre for open electronic publishing- is the platform for journals
        in the humanities and social sciences, open to quality periodicals looking to publish
        full-text articles online.</p>
      </projectDesc>
    </encodingDesc>
    <profileDesc>
      <langUsage>
        <language ident="en">en</language>
      </langUsage>
      <textClass>
        <keywords xml:lang="en">
          <term>TEI</term>
          <term>Listserv</term>
          <term>character</term>
          <term>email</term>
          <term>computer-mediated communication</term>
        </keywords>
      </textClass>
    </profileDesc>
    <revisionDesc>
      <change when="2025-03-06" who="#sb">Submitted to JTEI</change>
      <change when="2025-02-08" who="#sb">Started jTEI article outline based on Buenos Aires talk</change>
    </revisionDesc>
  </teiHeader>
  <text>
    <front>
      <div type="abstract" xml:id="abstract">
        <p><q>Can the archives of an email list be stored in TEI?</q> This paper 
          addresses this question with special attention to the challenges of data retrieval from
          the TEI-L Listserv, and the mapping of email contents and metadata to XML and TEI. 
          Our experiments with TEI data modeling involve adapting encoding models from the new
          <title level="a">Computer Mediated Communication</title> chapter, as well as 
          correspondence and personography in the <title>TEI Guidelines</title>. We experimented
          with very different approaches in retrieving and mapping Listserv data, and we faced challenges
          that reflect changing technologies in character encoding and email transmission, as well as
          conceptual difficulties in reliably tracing individual contributions over years and decades. 
          Ultimately we believe that yes, it is possible (although difficult) to store the archives of an email list in TEI,
          that there are some problems with establishing a satisfactory encoding, 
          and the methods one chooses will likely depend on the scope of a Listserv archival project.</p>
      </div>
    </front>
    <body>
      <div xml:id="introduction">
        <head>Introduction</head>
        <p>One of the priorities of digital humanities is cultural memory. It is a
        common goal to preserve the results of humanistic endeavors in
        a format suitable for scholarly examination and inquiry that may be 
        easy to access many years in the future. From the last quarter of 
        the twentieth century to the present, one venue for communication 
        among humans has been email, and in particular the email discussion list. 
        Digital humanists will likely want to preserve the data of email
        discussion lists in a way that is likely to survive the ups
        and downs of the software market and is amenable to
        scholarly processing.</p>
        <p>It may be surprising that the Text Encoding Initiative
        does not yet provide a dedicated mechanism for encoding email.
        TEI does provide mechanisms for encoding
        <emph>physical</emph> letters and chains of
        correspondence. Certainly there are quite a few similarities between letters
        and email. Like a letter, a piece of email is written by an author and sent to a
        recipient at a particular point in time. But physical letters
        do not have such a sharp demarcation between data &amp;
        metadata, rarely contain multiple copies of the same content in
        different formats (typically HTML and plain text), and never
        suffer character encoding ambiguities. Conversely, email does
        not have seals or stamps or quite the same kinds of inconsistencies we expect to see
        in any set of manuscripts.</p>
        <p>As of 2024, TEI now provides a mechanism for encoding
        computer-mediated communication (CMC). It is intended,
        however, for systems like Twitter or Tik-Tok rather than for
        email, and it is not yet known how well its encoding system
        could be applied to email. Thus the impetus for this project:
        can TEI, with its new CMC chapter, be used to encode an email
        discussion list?</p>
        <p>We decided the TEI-L discussion list would make an
        excellent test case. It is a large resource that spans decades
        from mailing list
        software (Listserv) with which we are somewhat
        familiar. Furthermore, because we had recently moved the list
        from Brown University to Penn State University, accessing
        the raw archives from its beginning to the day the list was
        moved would be trivial. But most of all, the list is
        obviously of significant interest to the TEI community. For us, its
        contents comprise a heritage <q>dig site</q> of resources and perspectives from the early
        days of text encoding and digital humanities. The first post was on 
          <date when="1990-01-08">Monday, 08 January 1990<!-- while I was still living in Pasedena, 6 days after I
        got my MICP certification —sb --></date>, so the list was
        started months before the first edition of P1, and years
        before the advent of XML.</p>
        <!-- gold mine; heritage dig site; digital archaeology -->
        <p>Our initial thought was that converting the data to XML would be easy,
        and that most of our attention would be directed towards the more interesting
        problem of deciding exactly how to encode it in TEI. However, it turns
        out that both parts were problematic. It was very difficult to convert
        the data into XML, and in several cases there is no TEI encoding that is
        really satisfactory.</p>
        <p>We took two approaches to encoding the TEI-L Listserv data in TEI:
        <list>
          <item>a craft encoding of a <q>core sample</q> of the list, 
            holding a short range of months or years worth of posts.</item>
          <item>an automated conversion of mass data to a basic
          TEI representation for archiving and potential later
          enhancement</item>
        </list>
        </p>
      </div>
      <div xml:id="data-retrieval">
        <head>Conversion from Source to XML</head>
        <div xml:id="scraping">
          <head>Scrape from the Web (attempted) Approach</head>
          <p>In an effort to retrieve some <q>core samples</q> to support the craft encoding approach and 
            retrieve all the  messages in a selected range of months or years, 
            we attempted to <q>scrape</q> these from the web archive of the TEI-L, which can be  
            accessed on the web in its current home at Penn State University at 
            <ref target="https://lists.psu.edu/cgi-bin/wa?A0=TEI-L">https://lists.psu.edu/cgi-bin/wa?A0=TEI-L</ref>.
            By adjusting this public web URL, one could retrieve a <q>core sample</q> from the TEI-L by entering a date range, such that
            if one were seeking to retrieve all of the messages between January and March of 1990, the URL that serves these is:
            <ref target="https://lists.psu.edu/cgi-bin/wa?A1=199001-199003&amp;L=TEI-L">https://lists.psu.edu/cgi-bin/wa?A1=199001-199003&amp;L=TEI-L</ref>.
            A significant limitation of this approach, at least in Listserv 17.0 currently used by Penn State, 
            is that the website access to the archives limits the number of results on a screen so that when large quantities of messages 
            (say over 100) are retrieved, some results can only be retrieved on click of a <q>next</q> button.
            In a programmatic scraping context, this posed some obstacles:
            <list>
              <item>With no clear way to request all the results in a single output, we would have to programmatically anticipate how to 
              locate the last entry and retrieve those that follow it.</item>
              <item>Outputs are alphabetically sorted by the first portion of the sender’s name (often a first name, but sometimes a surname), when one would expect them to be chronologically sequenced. 
                (This is not a serious problem because we could control sorting the output in the scraping process). </item>
            </list>
            
            We expect it is possible to overcome these difficulties, but due to time constraints in launching this project for the 2024 TEI Conference, 
            we limited ourselves to small samples that would be retrievable on one screen to simplify our processing requirements. We tinkered with the Scrapy Python library and lxml e-tree for parsing XPath, after a 
            false start in attempting to adapt <ref target="https://github.com/gaalcaras/mailingListScraper">an excellent scraper designed by GitHub user gaalcaras for retrieving messages from Hypermail</ref>, which produces a much simpler web archive than Listserv.</p>
          <p>Our limited scraping exercise helped us to learn about
          the Listserv web archive retrieval system.  What was most
          interesting to us about this method was the discovery that
          Listserv provides each message a distinct identifier for
          retrieving it for web view.  If we could retrieve the
          distinct identifiers from URLs and CGI paths, they could be
          a reliable way to pull message metadata and content.  On the
          archive results page for a search parameter, we found
          regular structures as seen in <ptr type="crossref"
          target="#scraped"/> (retrieved from a search for all of the
          1990 messages from January to December). All message data
          is provided in an HTML table, with each row sharing
          information about each message, including a bit of the
          message text content to be shown on mouseover, sender name
          and email, a date and time stamp (though it is unclear
          whether this is for circulation by Listserv or from the
          original email heading), and finally an HTML anchor pointing
          to a CGI path to retrieve the message with a distinct
          identifying string, as shown here:
            <figure xml:id="scraped">
           <egXML xmlns="http://www.tei-c.org/ns/Examples"> 
            <tr>
              <td class="emphasizedgroup row-l" scope="row"><div class="archive forcewrap"><span onmouseover="showDesc('Dear Colleague:&amp;lt;br&amp;gt;&amp;lt;br&amp;gt;From 27 May to 29 June 1990 I am out of the country and so gone from&amp;lt;br&amp;gt;this address, chiefly to attend the ALLC/ICCH conference in Siegen,&amp;lt;br&amp;gt;Germany. Mail will be kept faithfully for me here, but if I do not&amp;lt;br&amp;gt;reply to your message in early July, please resend your message then. [...]','Re: where is SGML being used','Fri, 29 Jun 90 13:19:30 EDT')" onmouseout="hideDesc()"><a href="/cgi-bin/wa?A2=TEI-L;5bb4caca.9006&amp;S=">Re: where is SGML being used</a></span></div></td>
              <td class="emphasizedgroup row-l"><div class="archive forcewrap">Willard McCarty &amp;lt;MCCARTY@VM.EPAS.UTORONTO.CA&amp;gt;</div></td>
              <td class="emphasizedgroup nowrap row-l"><div class="archive forcewrap">Fri, 29 Jun 90 13:19:30 EDT</div></td>
              <td class="emphasizedgroup right row-l"><a href="/cgi-bin/wa?MD=TEI-L&amp;i=9006&amp;I=1741011559&amp;s=204&amp;l=16&amp;X=O96EB1622E3EEE9B193&amp;Y=eeb4%40psu.edu&amp;URL=A1%3D199001-199012%26L%3DTEI-L%26s%3D0%26X%3DO96EB1622E3EEE9B193%26Y%3Deeb4%2540psu.edu&amp;M_S=Re%3A+where+is+SGML+being+used&amp;M_F=Willard+McCarty+%26lt%3BMCCARTY%40VM.EPAS.UTORONTO.CA%26gt%3B&amp;M_D=Fri%2C+29+Jun+90+13%3A19%3A30+EDT&amp;M_Z=16+Lines&amp;A1DATE=&amp;A2URL=https%3A%2F%2Flists.psu.edu%2Fcgi-bin%2Fwa%3FA2%3Dindex%26L%3DTEI-L%26O%3DA%26X%3DO96EB1622E3EEE9B193%26Y%3Deeb4%2540psu.edu%26s%3D0%26P%3D17156">
                  <img src="/archives/images/default_archive_delete_22x22.png" alt="Delete Message" title="Delete Message" /></a></td>
            </tr>
            </egXML>
            <head type="legend">Scraped Message Metadata</head>
            </figure>
            
            The cgi-bin locational information is certainly complicated, but appears to be parsable. The distinct identifier for a message can be found in the
            fourth and last <gi>td</gi> element by retrieving its child <gi>a</gi> and selecting the portion of its <att>href</att> attribute value that
            begins with <code>&amp;X=</code>, its X parameter. In this example Willard McCarty’s message happens to be the last on the first page of results, and 
            it is used again by Listserv within the value for its <q>Next</q> button to retrieve the results for the second screen.
            One can find it as the <q>X</q> parameter once again:
            <figure xml:id="nextButton">
            <egXML xmlns="http://www.tei-c.org/ns/Examples">
              <input type="button" value="Next Page &amp;#62;" 
                onclick="clearSessionStorage(); 
                goTo('/cgi-bin/wa?A1=199001-199012&amp;L=TEI-L&amp;s=250&amp;X=O96EB1622E3EEE9B193&amp;Y=eeb4%40psu.edu')" />
            </egXML>
            <head type="legend"><code>Next</code> Button Reproducing Message ID</head>
            </figure>            
            Our Python scraping experiment could follow these paths to
            extract URLs for messages, but we decided not to continue
            the experiment to try to extract Listserv’s web
            representation of the message data, because that data
            posed their own challenges for parsing <q>spaghetti
            code</q> and we could proceed more efficiently with a
            simpler resource for the email message data.  Because
            Listserv provides much cleaner and simpler monthly log
            text files on request that are far more tractable, we
            decided to work exclusively with the log files for
            experiments with converting to Listserv email data to
            TEI. You can explore <ref
            target="https://github.com/tei-cmc-experiment/tei-cmc-experiment/tree/main/logs">the
            log files for the year 1990</ref> in our GitHub repository
            and see how much simpler they are to work with as a basis
            for conversion. What is missing in those logs, however, is
            Listserv’s distinct identifier for each
            message.<note>~41.2% of email messages in the entire
            dataset have a <code>Message-ID</code> header field which
            provides a unique identifier for the message. But this is
            not the same identifier Listserv uses for its display, and
            over half of them are missing, making this field not
            useful for some purposes.</note> So for a future
            experiment, we may pull the message identifiers from
            Listserv’s web archive files in order to key the logs to
            the web retrieval system.</p>
        </div>
        <div xml:id="mass-conversion">
          <head>Mass Conversion Approach</head>
          <p>Our goal for the mass conversion approach was to
          programmatically convert all of TEI-L from its inception up
          to <date when="2024-04-29">Monday, 29 April 2024</date> into
          some form of simple, basic TEI using XSLT. That end date was
          chosen because it was the day the mailing list was moved
          from Brown University’s Listserv to Penn State University’s
          Listserv. This fact meant we could obtain the entire dataset
          as text files directly from the Brown listmaster without
          needing to worry about merging in data from PSU or about
          posts made just after we obtained the data. Peter DiCamillo,
          the Brown listmaster, sent us 412 separate files, one for
          each month, i.e., <name>tei-l.log9001</name> through
          <name>tei-l.log2404</name>. These data are also available by
          GET requests from the API service of LISTS.PSU.EDU. For
          details see the <gi>samplingDecl</gi> in our example in <ptr
          type="crossref" target="#TEI-collection"/>.</p>
          <p>The first step was to rename the log files to use 4-digit
          (as opposed to 2-digit) years so that they sorted into the
          correct order.<note>This was done quite easily in Emacs
          using dired-mode. But in fact, it is not very hard to do
          directly in the shell (the single command
          <eg>
            for f in tei-l.log* ; do
               echo "---------${f}:" ;
               if [[ ${f} =~ tei-l.log(9[0-9])([0-9][0-9]) ]] ; then
                  mv ${f} tei-l.log_19${BASH_REMATCH[1]}-${BASH_REMATCH[2]} ;
               elif [[${f} =~ tei-l.log([012][0-9])([0-9][0-9]) ]] ; then
                  mv ${f} tei-l.log_20${BASH_REMATCH[1]}-${BASH_REMATCH[2]} ;
               fi ;
            done</eg>
          does a nice job), and there are utilities
          available for Mac OS that could do this.</note> This
          renaming allowed the logs to be easily examined in a
          reasonable order and, more importantly, allowed them to be
          combined into a single file in the correct order using one
          simple command: <code>cat tei-l.log* >
          TEI-L.txt</code>.<note>In fact, in a vain effort to avoid
          the character encoding problems described below, we actually
          used <code>iconv -f ISO-8859-1 -t UTF-8 -c tei-l.log* >
          TEI-L.txt</code>, but we do not think it made any
          significant difference.</note></p>
          <div xml:id="post_delimiters">
            <head>Delimiters</head>
            <p>Each log file provided by Listserv contains one or more
            posts to the mailing list. For our dataset, the range was
            1–420 posts per monthly log file, although in several cases
            there is a month that has no postings, for which Listserv
            did not generate a .log file at all.</p>
            <p>Thus an early task was to figure out how posts are
            separated in a log file. Upon inspecting the dataset, it was
            quickly apparent that Listserv uses a string of 73 equal
            signs (U+003D, <q>=</q>) in a row as a start-post
            indicator, because there is such a delimiter before the
            first and every subsequent post in a file, but not after the
            last.</p>
            <p>But, of course, there is nothing to stop a mailing list
            user from including a string of 73 equal signs inside her
            post. We first checked (out of curiosity) to see if any
            strings of 73 equal signs were obviously <emph>not</emph>
            post delimiters, because they did not occupy the entire
            record. A search for the delimiter string (using just
            <code>egrep -c</code>) revealed that it occurs 31,031 times
            in the dataset; a search for the delimiter string anchored
            to the beginning and end of the line revealed that it occurs
            alone on a line 30,998 times. So there are 33 cases of 73
            equal signs in a row that do not occupy the entire record,
            and thus are not start-of-post indicators. (It is likely
            they exist as cases of posts being copied-and-pasted into
            other posts.)</p>
            <p>But are there any cases of 73 equal signs in a row that
            do occupy the entire line, but are <emph>not</emph> intended
            to be a start-post delimiter? We know that every email
            message (and thus every post to an email list) starts with
            a sequence of metadata records. Email metadata records are
            in a very specific format: the field name, which must be
            composed of one or more of the printable 7-bit ASCII
            characters except colon, followed by a colon, followed by a
            field body. On a quick examination of the dataset, it
            appears that the first field in every case is the
            <code>Date:</code> field. So we searched for occurrences of
            73 equal signs that start at the beginning of a line and are
            followed immediately by a newline followed by something
            <emph>other</emph> than an uppercase <q>D</q>.<note>That is,
            we searched for the regular expression
            <code>^={73}\n[^D]</code>.</note> There are only three such
            cases, so we just examined each of them.</p>
            <p>The first is simply a case of cut-and-paste: on <date
            when="1992-09-10">Thursday, 10 September 1992</date> Wendy Plotkin, who
            was at the time a PhD candidate in History at UIC and who
            served as the TEI’s research assistant (1990–1999), posted
            email that contained a copy of email from Professor Robert
            Jones of the University of Illinois Urbana-Champaign to a
            CETH mailing list, including a line of 73 equal signs which
            was used to separate the part she wrote from the part
            Professor Jones had sent.</p>
            <p>The other two cases are both of two lines of 73 equal signs
            in a row, with nothing between. Whether these indicate that the
            preceding post ended with the same set of characters that is
            used as the start-post delimiter, or that there is a missing
            post, we do not know.</p>
            <p>So the result of this analysis was that a line of 73
            equal signs in a row could be used reliably to indicate the
            start of a new post, with one exception, which we simply
            changed by hand to a line of 72 equal signs. (This is
            visually the same for a human reader, but distinctly
            different to a computer looking for 73 of them.) We also had
            to be prepared for the possibility of two such lines in a
            row.</p>
          </div>
          <div xml:id="characters_illegal">
            <head>Illegal Characters (for XML)</head>
            <p>Early email systems used ASCII (7-bit) characters
            only. Thus there were 128 available code points (0–2⁷-1, or
            0–127). Of those 128 available code points, only 99 of them
            are legal XML characters. The remaining 29 characters (for
            which see <ptr type="crossref" target="#appendix01"/>) are
            all non-printing control characters, intended for
            controlling the behavior of a peripheral device such as a
            card punch or printer, or (in a few cases)
            whitespace.<note>It is quite reasonable, in our opinion, for
            an astute reader of the XML specification to think that
            production 14 implies that <emph>any</emph> character (other
            than <code>&lt;</code> and <code>&amp;</code>) is allowed as
            data content. But production 14 needs to be read within the
            limits already established by production 2 — which prohibits
            these control characters.</note> While neither of us is an
            expert on early email systems, we suspect that the
            designers never intended these characters to be used in
            email, but did not feel it necessary to do anything to
            prevent them from being used, as the average user of a
            computer had no way of typing them, and thus would find it
            very difficult to get them into an email.<note>In fact,
            early definitions of email messages assert they are just a
            sequence of ASCII characters in the range of 1–127; see <ref
            type="bibl" target="#RFC2822">rfc2822</ref>. Later
            RFCs updated this to say <q><!-- uote source="#RFC5322"-->the use of US-ASCII control
            characters (values 1 through 8, 11, 12, and 14 through 31)
            is discouraged since their interpretation by receivers for
            display is not guaranteed.</q></note>
            </p>
            <p>Nonetheless, of the 29 characters that are not legal in
            XML, 17 of them occur in the TEI-L archives:
            <list>
              <item>64 occurrences in 34 posts before 2000 (which, on reflection, was not too surprising)</item>
              <item>38 occurrences in 11 posts after 2008 (which we did not expect at all)</item>
            </list>
            These characters were generally used not to represent the
            control characters to which they are mapped in the ASCII
            character set, but rather to represent various accented
            characters that were not part of the original (7-bit) ASCII
            set. Often these characters occurred within text that was
            likely copied-and-pasted from another source (e.g., from a
            conference announcement). The last use of a character that
            is illegal in XML was on 2016-03-13.</p>
            <p>An input document that contains illegal characters
            <emph>cannot</emph> be processed by XSLT, whether it is in
            an XML file or a plain text file. And, of course, such
            characters cannot occur in an XML file whether that file is
            generated by XSLT, XQuery, Python, C, or by hand in a text
            editor. In some of those languages, or using a text editor,
            you could <emph>put</emph> them into a file that has a
            <q>.xml</q> extension, but the file would not meet the
            definition of an XML file, and thus could not be processed
            by conforming XML software (other than to emit an error
            message).</p>
            <p>These control characters are being used incorrectly, and
            are not allowed in XML, but they are not mal-formed or
            illegal Unicode characters—they are perfectly legitimate
            Unicode characters that are not allowed in XML. Thus
            oXygen’s otherwise useful <name>Encoding errors
            handling</name> feature is not helpful here, as it relates
            to oXygen’s processing of mal-formed Unicode
            characters. Likewise a utility like <name>iconv</name>,
            which converts text from one character encoding to another,
            is of little to no use because these control characters are
            problematic no matter what character encoding is used to
            represent them.</p>
            <p>We immediately envisioned several possible solutions,
            each of which would have to be carried out on the plain text
            input files prior to processing into XML.
            <list rend="ordered">
              <item>Delete the problematic characters, leaving users to
              figure out what was missing and where. This lossy
              methodology seemed like a bad idea.</item>
              <item>Replace each of the 102 occurrences of the 17
              problematic characters with a single
              <soCalled>warning</soCalled> character. This would allow
              users to immediately know where there was a problem, but
              would leave solving it (i.e., figuring out which character
              belonged there) to the user. It requires, of course, that
              we use a character that does not occur in the data. (One
              obvious choice, for example, would be <q>⚠</q> (U+26A0),
              but it already occurs three times in the input dataset.)
              This is obviously better than just deleting the
              characters, but still puts effort on the reader.</item>
              <item>Replace the problematic characters with 17 different
              <soCalled>warning</soCalled> characters. We believe some
              users would find decoding this a lot easier, but others
              would find it more difficult (because it did not seem to
              be the case that there was always a 1:1 relationship
              between the control character used and the desired
              character). This also would mean that we would have to
              find 17 characters that would be clear to the user, but do
              not occur in the input dataset.</item>
              <item>Replace the problematic characters with 17 different
              <soCalled>warning</soCalled> <emph>strings</emph>. After
              all, XML does have a replacement mechanism. So if we were
              to replace each of the six occurrences of, say, U+001A with
              <q>&#x2A00;SUB&#x2A00;</q> in the input document, we could either leave
              them that way for the user, or convert them to
              <q>&amp;SUB;</q> and provide an appropriate declaration,
              <?jtei Note to JTEI editors: This is weird. The
                characters I wanted to use (U+26D1 & U+E503) do not
                survive FOP processing. So I switched to using U+2A00
                for both. The two occurrences aboves survive, but the
                one below gets converted to # (U+0023)! Is that
                because it is within a <code>, and thus using a
                different font? ?>
              for example to a PUA character: <code>&lt;!ENTITY SUB
              "&#x2A00;"></code>. This would likely be easier for
              readers than using a single character for each of the 17
              problematic characters, but as with that solution readers
              would be confused when there was not a 1:1 mapping from
              the strings we provide and the likely intended
              characters.</item>
              <item>For each occurrence of a problematic character, try
              to figure out what character the author intended, and
              replace it with that (proper UTF-8) character. While this
              involves far more work than any of the above, we feel this
              option results in documents that are easier for users to
              process and read.  We considered four variations on this
              theme, based on two binary features:
              <list rend="bulleted">
                <item>in each case, try contacting the author to ask
                what was the intended character, or not;</item>
                <item>in each case, just replace the problematic
                character with our guess at the correct desired
                character, or replace it with a <gi>choice</gi> encoding
                which records both the original character (e.g., as
                <code>&lt;orig>&lt;g type="CONTROL"
                subtype="FS"/>&lt;/orig></code>) and our regularization
                thereof (e.g., as
                <code>&lt;reg>&#x00A3;&lt;/reg></code>).</item>
              </list>
              While we think that contacting the original authors is, in
              some cases, beneficial, and believe that the
              <gi>choice</gi> encoding is by far the best way of
              representing the problematic characters, for our small
              experiment we chose the easier route for each of these
              features.<note>As it is, finding the problematic
              characters, figuring out what each was likely supposed to
              be (often by multiple visits to the <ref
              target="https://webcf.waybackmachine.org/">Internet
              Archive’s Wayback Machine</ref>), and replacing them took
              multiple hours.</note></item>
            </list>
          </p>
          <p>After replacement of those characters that are illegal in
          XML by those characters we thought they should be, the input
          dataset was easily read by XSLT. Converting that to useful,
          readable XML presented some challenges, though.</p>
        </div>
        <div xml:id="memory">
          <head>Java, and Memory, and Streams, oh my!</head>
          <p>We quickly discovered that processing the entire ~151 MiB
          of data at once requires a lot of RAM, more than Saxon gets
          from the Java virtual machine by default. There are three
          obvious solutions to this problem.
          <list rend="ordered">
            <item>Chop up the data: Rather than reading in a single
            file of ~151 MiB of data, use perhaps 10 files of ~15
            MiB each (or vice-versa); or even use the original 412
            files (the largest of which is ~4 MiB) generated by
            Listserv.</item>
            <item>Use streaming XSLT: The whole point of the
            <soCalled>streamability</soCalled> feature of XSLT 3.0
            is to be able to process large, perhaps infinitely
            large, datasets in memory.</item>
            <item>Give the Java virtual machine more heap space.</item>
          </list>
          </p>
          <p>Using smaller chunks of input seems like a very good
          approach in the general case. We did not follow that route
          simply for the sake of expediency: we had already put in
          hours of effort on the combined ~151 MiB file of data
          (searching for and changing characters illegal for XML),
          and simply did not want to take the time to artificially
          divide the data into multiple files and then change our
          XSLT program so it would iterate over them. That said,
          this would be a reasonable approach were it not for the
          time constraints on our unfunded pilot project.</p>
          <p>We <emph>think</emph>, but are not at all convinced,
          that the use of streaming XSLT would solve this problem.
          Although the data we are reading in is not XML, it is
          internally converted to XML and then processed in several
          stages. It is likely that if these stages were streamable
          the memory use would be dramatically decreased. However,
          neither of us is particularly well versed in writing
          streamable XSLT, and, perhaps more importantly, do not
          (yet?) consider it a viable solution for digital
          humanists, as the only XSLT processors in the world that
          have this feature are payware.</p>
          <p>So while we admit it may be rude to require a user of
          our program to do so, we simply increased Java heap space to 5 GiB
          when running this transformation.</p>
        </div>
        <div xml:id="dates">
          <head>Date Inconsistencies</head>
          <p>We think it is a given that having a machine-actionable
          date &amp; timestamp for each posting is an important
          feature of a preservation format for an archive of email
          messages. In TEI such a timestamp is typically stored on a
          <att>when</att> attribute in the W3C format (itself a subset
          of ISO 8601:2000 2nd edition format).</p>
          <p>Early on in the development of our XSLT program we were
          quite worried about how to go about parsing the values of
          the <code>Date:</code> header fields. While the format of
          this field is reasonably strictly defined by <ref
          type="bibl" target="#RFC5322">rfc5322</ref>, that standard
          was not published until 2008, 18 years after the TEI-L mailing list was
          started. We expected the given dates to be in dozens of different,
          potentially incompatible, formats.</p>
          <p>After some analysis we were pleasantly surprised to find
          that only 21 different formats were represented in this
          dataset. (The frequency of each format is listed in <ptr
          type="crossref" target="#appendix02"/>.) Interestingly, most
          of the variation was in the time zone. Discounting that
          variation, there were only four different formats. The
          variation in time zone indication, however, was at times
          ambiguous. For example, the time zone <q>BST</q> appears in
          the <code>Date:</code> field of over twenty posts. Given
          that the TEI was partially based in Great Britain, it is
          very likely that <q>BST</q> means <q>British Summer Time</q>
          (+01:00). But it is also used for <q>Brazilian Summer
          Time</q> (-02:00), <q>Bangladesh Standard Time</q> (+06:00),
          and <q>Bougainville Standard Time</q> (+11:00).</p>
          <p>In the end, we were able to parse all 38,787
          <code>Date:</code> fields using the regular expression
          capability of XSLT 3.0, plus a pair of maps to convert month
          names to 2-digit numbers and the various time zones we had
          found in our analysis to the correct format. Some of those
          time zone mappings were guesses based on the top level
          domain of the email addresses that had sent mail with an
          ambiguous time zone.<note>Thanks to our transformation to
          TEI, it took us only minutes to discover that of the 38,787
          timestamps for all posts, 38,716 (99.8%) have an on-the-hour
          time zone indication, 51 (0.1%) have no time zone
          indication, 19 have an on-the-half-hour time zone
          indication, and 1 has a clearly erroneous time zone
          indication of <code>-00:08</code>. We expect that it
          would be easy to ascertain this using any of a variety of
          programming languages reading either the original dataset or
          our TEI encoded version. But given that we are experts in
          XPath and XSLT, having this information in TEI made this
          discovery very easy <emph>for us</emph>.<!-- It is worth
          noting that this cannot be done by just scanning the
          original dataset for the regular expression
          <code>^Date:</code> and parsing the rest of the line. There
          are nearly 700 lines that begin with <q>Date:</q> that are
          <emph>not</emph> the date of a posting. (Many are the date
          of an event being announced.) So the lines in the original
          dataset need to be parsed to separate email headers from
          email bodies. (Possibly only the lines that start with
          <q>Date:</q> could be further parsed, and maybe those that
          are dates of posts could be separated from the rest that
          way. We did not try, and do not intend to.) Besides, you
          would still have to normalize the time zones as they appear
          into the standard offset notation. --></note></p>
        </div>
        <div xml:id="conversion_complexities">
          <head>Unsolved Conversion Complexities: MIME</head>
          <p>MIME stands for <term>Multipurpose Internet Mail
          Extensions</term>, a set of extensions to email that allows
          for
          <list>
            <item>representation of more than just 7-bit US-ASCII characters in header field values</item>
            <item>representation of more than just 8-bit US-ASCII characters in mail bodies</item>
            <item>representation of content using systems other than
            just plain text, possibly as attachments (e.g., text/html,
            application/msword)</item>
          </list>
          These capabilities and the corresponding questions raised
          are discussed in the following subsections. But for us MIME
          may as well stand for <term>Major Incoherent Mess in
          Email</term>, because other than being able to parse out the
          various MIME parts of an email message body into separate
          constructs, we were not able to process MIME extensions at
          all in this limited pilot project.</p>
          <p>When MIME is used,<note>Which these days is essentially
          always. In our dataset ~92.6% of posts use MIME. The first
          1841 posts occurred over the first 2531 days (6.93 years) and
          did not use MIME; the first use of MIME was on <date
          when="1996-12-13">Friday, 13 December 1996</date>. Over the next 2531
          days 3327 of 3707 posts (89.75%) used MIME. Over the last
          2531 days in the dataset 4854 of 4861 posts (99.86%) used
          MIME.</note>
          <list rend="inline ordered">
            <item>a <code>MIME-Version:</code> field is present (its value is always <val>1.0</val>);</item>
            <item>the mail body is divided into 1 or more
            <term>parts</term>, each of which has some associated
            metadata of its own; and</item>
            <item>if there is more than 1 part, the
            <code>Content-Type:</code> field will start with
            <val>multipart/</val> and have a <code>boundary=</code>
            parameter, whose value can be used by mail clients (or
            intrepid digital humanists) to parse out the different
            parts.</item> </list> Furthermore, each part may itself be
            multipart, in which case it also has a
            <code>Content-Type:</code> field that starts with
            <val>multipart/</val> and a <code>boundary=</code>
            parameter. Thus the parts are arranged as a standard
            hierarchical tree, although in practice the tree often has
            only leaf nodes (i.e., parts that are not themselves
          multipart).</p>
          <div xml:id="Encoded-word_syntax">
            <head>ASCII Work-around: Encoded-word Syntax</head>
            <p>As mentioned above, early email used only 7-bit ASCII
            characters for the entire message. Later updates to the
            specifications allowed for the body of the email message
            to use a different character set, but the email headers
            (that is, the lines of metadata at the top) are still to
            this day limited to 7-bit ASCII. Most of the world’s
            printable characters, of course, are not available in that
            set of 96 printable characters. To allow for characters
            outside the 7-bit ASCII set to be used in email headers
            (e.g., in the name of the sender or recipient of an
            email), an escape system called <term>encoded-word
            syntax</term> may be employed. (See <ref
            type="bibl" target="#RFC2047">rfc2047</ref>.)</p>
            <p>Using this system, a word that contains a character
            outside of 7-bit ASCII is encoded as
            <code>=?charset?encoding?encoded text?=</code>, where
            <term>charset</term> is the character encoding in which
            the encoded text should be looked up,
            <term>encoding</term> is either <q>Q</q> (for a
            quoted-printable style escape mechanism) or <q>B</q> (for
            a base64 style escape mechanism), and <term>encoded
            text</term> is the string encoded using the escape
            mechanism indicated. The character sets employed in this
            dataset were as follows, ignoring case distinctions. (For
            example, UTF-8 was often spelled <q>utf-8</q>.)
            <table xml:id="char_encodings">
              <row role="label"><cell>character set (case regularized)</cell><cell>count</cell><cell>%</cell></row>
              <row><cell>UTF-8</cell><cell>2300</cell><cell>55.6%</cell></row>
              <row><cell>ISO-8859-1</cell><cell>1043</cell><cell>25.2%</cell></row>
              <row><cell>ISO-8859-2</cell><cell>383</cell><cell>09.3%</cell></row>
              <row><cell>Windows-1252</cell><cell>236</cell><cell>05.7%</cell></row>
              <row><cell>ISO-8859-15</cell><cell>132</cell><cell>03.2%</cell></row>
              <row><cell>ISO-8859-5</cell><cell>16</cell><cell>00.4%</cell></row>
              <row><cell>KOI8-R</cell><cell>5</cell><cell>00.1%</cell></row>
              <row><cell>big5</cell><cell>4</cell><cell>00.1%</cell></row>
              <row><cell>ISO-2022-jp</cell><cell>3</cell><cell> &lt; 1 ‰ </cell></row>
              <row><cell>Windows-1250</cell><cell>3</cell><cell> &lt; 1 ‰ </cell></row>
              <row><cell>ISO-8859-4</cell><cell>2</cell><cell> &lt; 1 ‰ </cell></row>
              <row><cell>Windows-1256</cell><cell>2</cell><cell> &lt; 1 ‰ </cell></row>
              <row><cell>Windows-1251</cell><cell>2</cell><cell> &lt; 1 ‰ </cell></row>
              <row><cell>Windows-1257</cell><cell>1</cell><cell> &lt; 1 ‰ </cell></row>
              <row><cell>X-UNKNOWN</cell><cell>1</cell><cell> &lt; 1 ‰ </cell></row>
              <row><cell>gb2312</cell><cell>1</cell><cell> &lt; 1 ‰ </cell></row>
              <row><cell role="label">total</cell><cell>4134</cell><cell></cell></row>
            </table>
            Dramatically more word-encoded passages in this dataset
            employ <q>Q</q> encoding over the <q>B</q> method: 3,397
            (82.2%) and 737 (17.8%), respectively.</p>
            <p>We recognized and considered the problem of passages
            represented with word-encoded syntax. Our instinct is that
            most digital humanists with an interest in this data
            would be better served by the results of our conversion
            process if we decoded these strings (for example,
            converted <q>=?UTF-8?Q?Piotr_Ba=C5=84ski?=</q> to <q>Piotr
            Bański</q>),<note>This name also appears as
            <q>=?ISO-8859-2?Q?Piotr_Ba=F1ski?=</q> and
            <q>=?UTF-8?B?UGlvdHIgQmHFhHNraQ==?=</q>.</note> and that
            those performing digital archaeology about how various
            characters were represented by various historical email
            systems would just as soon use the source data rather than
            the TEI-encoded output of our process. We are not
            convinced of this position, though, and did not have
            anywhere near enough time in this pilot project to attempt
            to write a word-encoded syntax decoder in XSLT.</p>
          </div>
          <div xml:id="MIMEsep">
            <head>Separating MIME Parts</head>
            <p>Email that uses MIME is divided into one or more
            <term>parts</term>, each of which contains a singe type of
            data. The most common types in our dataset are text/plain
            and text/html; much less frequent are text/enriched,
            text/x-vcard, text/xml, and application/*.</p>
            <p>It would not be unreasonable to put all the different
            MIME parts of a post to the Listserv as raw data into a
            single TEI <gi>div</gi> or <gi>post</gi> element. It would
            certainly be easier than trying to parse the parts into
            separate TEI elements. But this <foreign
            xml:lang="la">caveat emptor</foreign> approach, while
            possibly useful for preservation of the data, would 
            yield data that was not at all amenable to scholarly
            processing.</p>
            <p>It would also be reasonable to ignore all MIME parts
            other than text/plain — after all, this is the
            <emph>Text</emph> Encoding Initiative version of the data
            we are creating. (In fact, this is what we did for the
            <soCalled>scrape + craft encoding</soCalled> approach
            described in <ptr type="crossref" target="#scraping"/>, except
            there all parts were ignored except the one the Listserv
            web interface chose to display.) But it would also
            be quite reasonable, and quite possibly helpful to future
            scholars and interested parties, to retain the information
            in other parts of postings to the mailing list. But doing
            so presents interesting practical and theoretical
            challenges.</p>
            <p>The practical challenges can be divided into two broad
            categories: <list rend="inline"><item>parsing the content
            of the email into its separate MIME parts, and
            </item><item>processing the content of each MIME part
            according to its type</item></list>. We were able to
            partially solve the first challenge within the scope of
            this small pilot project. Our XSLT will recognize MIME
            multipart content, and separate out each of the
            highest-level parts into their own constructs. However, it does
            not yet handle multipart-inside-multipart MIME content.</p> 
            <p>The second practical challenge, processing the content
            of a MIME part according to its type, is reasonably easy
            to contemplate for XSLT when the content type is
            text/* or application/xml. But in almost all other cases
            conversion to something tractable by XSLT is at best
            difficult.</p>
            <p>The theoretical challenges strike us as very
            interesting, and they boil down very simply to a question 
            of what to do with data other than plain text. Some datatypes easily lend
            themselves to TEI encoding; counter-intuitively, these are
            the datatypes for which there is really no reasonable XML
            representation. Imagine, for example, that one of the MIME
            parts is of type image/jpeg or audio/ogg. (None of them
            are, as the rules of this particular mailing list
            disallowed most binary attachments to help prevent the spread
            of malware.) The only real possibilities are <list
            rend="inline"><item>to ignore it, </item><item>to put the
            binary data in a separate .jpg or .ogg file and point to
            it, or </item><item>to encode the data in a
            <gi>binaryObject</gi> element.</item></list></p>
            <p>But what of data typed as some form of text other than
            text/plain? In many cases, the MIME part is another
            representation of the same content as a text/plain MIME
            part. (This allows a client that knows how to display,
            say, text/html to do so, but a client that does not have
            that capability to display the text/plain content.) In
            which case, should it be included in the TEI version of
            the archive at all? It would certainly be easier to simply
            ignore the HTML version. But the author of the email may
            well have used an editor that allowed certain styling
            (like italics, change in font size, change in font color,
            etc.), and that styling is likely available in the HTML
            but not the plain text. Moreover, that styling may be of
            interest to future scholars. But what TEI constructs
            should the HTML be converted into? HTML to TEI conversion
            is not at all a simple task. (For starters, HTML permits
            headings in the middle of divisions; and the table models,
            while similar, are not the same.) One possibility, of
            course, is to move the HTML into a separate file, and
            point to it from the TEI. (This also has the advantage of
            avoiding the problem of what to do with ill-formed
            HTML.)</p>
          </div> <!-- ebb: Read/revised to here 2025-03-04 @ 16:10 JST. -->
          <div xml:id="content_encoding">
            <head>Content Encoding</head>
            <div xml:id="CE_intro">
              <head>Why Content Encoding is Required</head>
              <p>Email servers, etc., use at most 8 bits per
              character. (And, as pointed out in <ptr type="crossref"
              target="#Encoded-word_syntax"/>, only 7 bits per
              character in the header.) It is possible to represent
              256 characters in 8 bits. Thus any message body that
              contains any of the other 154,807 characters needs to be
              down-translated into only those 256 characters. MIME
              permits two different methods for performing this
              down-translation: <term>quoted-printable</term> and
              <term>base64</term>. For the actual definitions of these
              formats see <ref type="bibl"
              target="#RFC2045">rfc2045</ref> sections 6.7 &amp; 6.8,
              respectively.</p>
              <p>Note that using the specified down-translation method
              to recover the correct character codepoints is not
              sufficient to decode the message body. The client must
              also know which character set to use to map each
              codepoint to a character. For example, in the ISO 8859-2
              character set the codepoint 241 (hexadecimal F1)
              represents <q>ń</q>; in UTF-8 it represents
              <q>ñ</q>. Which character set to use is specified on the
              <name>Content-Type</name> header field. For example,
              <code>Content-Type: text/plain;
              charset=ISO-8859-1</code> specifies the ISO 8859-1
              character set.</p>
            </div>
            <div xml:id="quoted-printable">
              <head>Quoted-printable</head>
              <p>The quoted-printable method is, at its core, quite
              simple. Any sequence of 8 bits (an octet, the base 2
              version of a number from 0 to 127, and on most systems a
              byte), except for the octets reserved for signaling
              end-of-line, is represented instead by an equal sign
              (U+3D, <q>=</q>) followed by two (upper case)
              hexadecimal digits. Thus when US-ASCII, UTF-8, or any of
              the ISO-8859 character sets are in use, the letter
              <q>n</q> may be represented by <q>=6E</q>, because the
              codepoint for <q>n</q> is 110 (equal to hexadecimal 6E)
              in each of those character sets. When the UTF-8 character set is in use,
              <q>=C5=84</q> can be used to represent <q>ń</q>, because
              the codepoint 324 (hexadecimal 0144) is mapped to
              <q>ń</q> in Unicode; 324 is too large to be represented
              in a single octet, so it is broken up into two.<note>The
              octets are 11000101 10000100. In the first octet the
              first 3 bits (110) assert that this number is expressed
              in 2 octets, the last 5 bits (00101) are the first 5
              bits of the codepoint number. In the second octet the
              first 2 bits (10) are the signal that this is a continuation of
              the previous octet, and the last 6 bits are the
              last 6 bits of the codepoint number. Thus we can read
              this UTF-8 character expressed using two bytes as the
              11-bit binary codepoint 00101000100, which is 324 in
              decimal or 144 in hexadecimal.</note></p>
              <p>This system, if used as described above, would result
              in an encoding that is three times larger than the
              unencoded information (because every character is
              represented by an equal sign followed by two characters,
              the hexadecimal digits) and impossible to read. So there
              is an important exception: any character from 33
              (hexadecimal 21, <q>!</q>) through 126 (hexadecimal 7E,
              <q>~</q>), inclusive, except for 61 (hexadecimal 3D,
              <q>=</q>, the equal sign) may be represented by
              itself. That includes the 26 letters of the US-ASCII
              alphabet in both upper &amp; lower cases. Thus
              <q>Espa=C3=B1ola</q> is normally used for the string
              <q>Española</q> rather than
              <q>=45=73=70=61=C3=B1=6F=6C=61</q>.<note>This means that
              when used on Western texts that have a high percentage
              of characters in the standard US-ASCII set,
              quoted-printable results in relatively easy-to-read,
              compact encodings. Sadly, however, when used on Cyrillic,
              Greek, or CJK text, or arbitrary binary data, the
              encoded version is both large and completely
              unreadable.</note></p>
              <p>There are several other details to quoted-printable
              encoding (whitespace, end of line, and soft line breaks
              to be precise) but this is the main gist of it.</p>
            </div>
            <div xml:id="base64">
              <head>Base64</head>
              <p>The base64 method of encoding content is also not
              particularly complex at its core. It has the advantages
              (over quoted-printable) of expanding input by a factor
              of ~133% rather than a factor of up to 300%, and of
              being easily applicable to arbitrary binary input (e.g.,
              JPEGs or OGGs); it has the disadvantages of being
              somewhat more complex, and is completely unreadable
              before decoding.</p>
              <p>In base64 the input is broken up into sets of 3
              octets (24 bits). Each set of 24 bits is then divided
              into 4 sets of 6 bits. A sextet gives you a range of 64
              numbers, 0–63. Each of those numbers is mapped onto a
              character that will survive transfer through an email
              system because it is the same in US-ASCII, ISO 646, and
              ISO 10646 (i.e., Unicode), etc.<note>The
              <soCalled>alphabet</soCalled> used to represent the 64
              possible values is <code>A</code>–<code>Z</code>,
              <code>a</code>–<code>z</code>,
              <code>0</code>–<code>9</code>, <code>+</code>, and
              <code>/</code>.</note> Each of those characters, of
              course, is represented by an octet in the encoded
              version of the data. So every 24 bits of unencoded data
              takes 32 bits to represent in the encoded form, hence
              the 33% increase in size.</p>
              <p>So the string <q>Española</q> is encoded in base64 as
              <q>RXNwYcOxb2xhCg==</q>. The equal signs are used at the
              end for padding, as the input could not be divided into
              an integral number of 3-octet sets. In addition to
              padding there are special rules for line length and line
              ends. But the above is the important basis of the
              system.</p>
          </div>
          <div xml:id="CE_lin">
            <head>Content Encoding, Lineation</head>
            <p>Whether quoted-printable or base64 encoding is used,
            each line of the body of the email can be at most 76
            characters long. Because base64 makes use of only 64
            characters (or 65 if you count trailing equal signs), none
            of which are whitespace, base64 encoded content often
            looks like a large block of undecipherable letters and
            numbers.</p>
            <p>Quoted-printable encoded content typically looks much
            more like the original content (because the whitespace and
            many letters are the same), but because the line length is
            limited to 76 characters, a special flag has to be used to
            signal when a single line of text has been encoded into
            two (or more) lines of encoded text. This flag is an equal
            sign (U+003D, <q>=</q>) at the end of a line. (It is
            usually, but not always, the 76th character.)</p>
          </div>
          <div xml:id="CE_xmp">
            <head>Content Encoding Examples</head>
            <p>In order to exemplify these content encoding methods,
            here we take a short snippet of sample text taken from a
            posting by Lionel Clement on <date
            when="1999-12-18">Saturday, 18 December 1999</date> in
            which the second call for papers for the the upcoming
            <name>TAG+5</name> conference is presented. The sample is
            shown here three times:
            <list rend="ordered">
              <item>Using multibyte characters (in UTF-8, as is this entire article).</item>
              <item>Using only 7-bit US-ASCII characters (i.e., every
              character is represented by an octet, of which the first
              bit is 0) with characters outside of US-ASCII
              represented using the quoted-printable algorithm.</item>
              <item>Also using only 7-bit US-ASCII characters, but the
              entire passage has been encoded using the base64
              algorithm.</item>
            </list>
            </p>
            <figure xml:id="charEnc01">
              <eg xml:lang="fr">
      DEUXIÈME APPEL À COMMUNICATIONS

   La cinquième conférence sur les grammaires d'arbres adjoints (TAG) et

autres formalismes proches (d'où le +) aura lieu à l'Université Paris
7 du 25 au 27 mai 2000 sous l'égide de l'ATALA (Association pour le
Traitement Automatique des Langues).
              </eg>
              <head type="legend">Snippet of plain text — 287 characters in 7 lines</head>
            </figure>
            <figure xml:id="charEnc02">
              <eg xml:lang="fr">
      DEUXI=C8ME APPEL =C0 COMMUNICATIONS

   La cinqui=E8me conf=E9rence sur les grammaires d'arbres adjoints (TAG)=
 et

autres formalismes proches (d'o=F9 le +) aura lieu =E0 l'Universit=E9 Par=
is
7 du 25 au 27 mai 2000 sous l'=E9gide de l'ATALA (Association pour le
Traitement Automatique des Langues).
              </eg>
              <head type="legend">Snippet in quoted-printable — 307 characters in 9 lines</head>
            </figure>
            <figure xml:id="charEnc03">
              <eg xml:lang="fr">
ICAgICAgREVVWEnITUUgQVBQRUwgwCBDT01NVU5JQ0FUSU9OUwoKICAgTGEgY2lucXVp6G1lIGNv
bmbpcmVuY2Ugc3VyIGxlcyBncmFtbWFpcmVzIGQnYXJicmVzIGFkam9pbnRzIChUQUcpIGV0Cgph
dXRyZXMgZm9ybWFsaXNtZXMgcHJvY2hlcyAoZCdv+SBsZSArKSBhdXJhIGxpZXUg4CBsJ1VuaXZl
cnNpdOkgUGFyaXMKNyBkdSAyNSBhdSAyNyBtYWkgMjAwMCBzb3VzIGwn6WdpZGUgZGUgbCdBVEFM
QSAoQXNzb2NpYXRpb24gcG91ciBsZQpUcmFpdGVtZW50IEF1dG9tYXRpcXVlIGRlcyBMYW5ndWVz
KS4K
              </eg>
              <head type="legend">Snippet in quoted-printable — 389 characters in 6 lines</head>
            </figure>
          </div>
          <div xml:id="CE_NOT">
            <head>Content Encoding—NOT!</head>
            <p>It is trivially easy to perform encoding or decoding of
            a quoted-printable or base64 encoded file because other
            people have written programs to do the work. In GNU/Linux,
            for example, the commands <code>qprint</code> and
            <code>base64</code> will perform either encoding to or
            decoding from quoted-printable and base64
            respectively.<note>In fact, these are the commands we used
            to generate the examples in the previous
            subsection.</note></p>
            <p>Furthermore, many modern programming languages have
            libraries with functions that perform quoted-printable or
            base64 encoding and decoding. But, as far as we can tell,
            XSLT is not one of them. Our reading of the XPath 3.1
            specification says that it provides the capability to
            encode a string of text <emph>into</emph> base64, but not
            to decode base64 data into a string. There is support for
            base64 using the <ref type="bibl"
            target="#EXPath">EXPath</ref> extensions to XPath.</p>
            <p>We did not attempt to decode quoted-printable or base64
            encoded content mostly due to a lack of time in this small
            pilot project. That said, we are hesitant to employ EXPath
            for a tool intended for digital humanists, as the only
            EXPath-capable processors we are aware of are payware.</p>
          </div>
        </div>
        </div>
      </div> <!-- conversion_complexities -->
    </div> 
    <div xml:id="mapping-to-TEI">
      <head>Mapping to TEI</head>
      <!--ebb: To start here. -->
      <p>In this section we represent some experimental modelings of email Listserv data in TEI encoding. 
        We experimented with a combination of encoding from the newly introduced chapter on Computer Mediated
        Communication (CMC) and from TEI encoding for correspondence. In each of the methods shared in this section, 
        we followed the guidance of the new Computer Mediated Communication chapter to store email postings at the 
        same hierarchical level, rather than permitting them to nest when posts reply to original posts. 
        This approach represents the email archive simply according to chronological sequencing of posts, without 
        attempting to cluster posts with their replies. It was easy to prepare the archive in this way working from
        our source documents, because the TEI-L log files that we worked with to prepare these examples 
        are arranged by chronological sequence and without topical nesting. 
        In the interests of facilitating comparison of our encoding decisions, we have truncated the body of each message
        in the examples to show only the first and last few lines.</p>
      
      <p>The email headers that were present in the entire dataset
      include the following information fields:
      <list>
        <item>Date</item>
        <item>From</item>
        <item>Reply-To</item>
        <item>Sender</item>
        <item>Subject</item>
        <item>MIME-Version</item>
        <item>Content-Type</item>
        <item>In-Reply-To</item>
        <item>Content-Transfer-Encoding</item>
        <item>Comments</item>
        <item>Message-ID</item>
        <item>Organization</item>
        <item>Content-Disposition</item>
        <item>X-cc (carbon copy)</item>
      </list>
      
 In our efforts to model these data, we initially found the following fields could neatly map to TEI constructions associated with 
 computer-mediated communication and correspondence encoding. However, they are not the only possible ways to apply the TEI to email data, 
 and our examples in the following sections will explore some variations, especially in developing the <gi>teiHeader</gi>. 

      <table xml:id="field_mapping1">
        <row role="label"><cell>email header field</cell><cell>TEI location (in XPath)</cell></row>
        <row><cell>Date</cell><cell><code>post/@when</code></cell></row>
        <row><cell>From</cell><cell><code>post/@who</code></cell></row>
        <row><cell>Reply-To</cell><cell><code>correspDesc/correspContext/ptr[@type="reply-to"]</code></cell></row>
        <row><cell>Sender</cell><cell><code>correspDesc/correspAction[@type="relayed"]/email</code></cell></row>
        <row><cell>Subject</cell><cell><code>post/head</code></cell></row>
        <row><cell>In-Reply-To</cell><cell><code>correspDesc/correspContext/ref[@type="in-reply-to"]</code></cell></row>
        <row><cell>Comments</cell><cell><code>correspDesc/correspAction[@type="orig-(to|cc)"]/email</code></cell></row>
        <row><cell>Message-ID</cell><cell><code>idno[@type="message-id"]</code></cell></row>
        <row><cell>Organization</cell><cell>[not yet represented]</cell></row>
        <row><cell>X-cc</cell><cell><code>correspDesc/correspAction[@type="orig-cc"]/email</code></cell></row>
      </table>
      Note the vast majority of the <code>Comments:</code> fields
      (~93.7%) reproduce the original <code>To:</code> field; in
      addition, all of the <code>X-cc:</code> fields and most of the
      remaining <code>Comments:</code> fields (~5.6%) reproduce the
      original <code>CC:</code> field. The original <code>To:</code>
      and <code>CC:</code> fields are otherwise not available in the
      archive.</p>
      
      <p>It is perhaps a little ironic that we prepared many of our examples for this paper from a 1990 conversation on TEI-L
        about encoding compound documents, given the compound nature of an email Listserv archive. In preparing distinct modelings 
        of a TEI archive, we followed the method of the Listserv monthly log documents that store the messages as a chronological sequence, 
        and we needed to make decisions about how to associate related messages that reply or respond to one another.</p>
     
     <div xml:id="TEI-collection">
       <head>One TEI Document for a Collection of Posts</head>
       <p>In one approach to mapping the metadata for a collection, we envisioned a single <gi>TEI</gi> element 
       holding a collection of <gi>post</gi> elements, each of which contains an email message. For this approach, we applied the <gi>teiHeader</gi>
       to store metadata about the original server location of the TEI Listserv and its log files in the <code>fileDesc/sourceDesc</code>.
       We encoded the method of our extraction of data from the TEI-L archive in the <code>encodingDesc/samplingDecl</code>, as shown in this example:
       
       <egXML xmlns="http://www.tei-c.org/ns/Examples">
         <teiHeader>
           <fileDesc>
             <titleStmt>
               <title>Text Encoding Initiative public discussion list: January and February 1990</title>
             </titleStmt>
             <editionStmt>
               <edition>Second experimental (“alpha”) edition</edition>
             </editionStmt>
             <publicationStmt>
               <authority>
                 <persName>Elisa Beshero-Bondar</persName>
                 <persName>Syd Bauman</persName>
               </authority>
               <date when="2024-09-22"/>
               <distributor><orgName>GitHub</orgName></distributor>
               <address>
                 <addrLine>88 Colin P. Kelly Junior Street</addrLine>
                 <addrLine>San Francisco, CA 94107</addrLine>
                 <addrLine>United States</addrLine>
               </address>
             </publicationStmt>
             <sourceDesc>
               <bibl>
                 <title level="j">TEI-L Listserv</title>
                 <title level="s">LOG9001</title>
                 <title level="s">LOG9002</title>
                 <publisher>University of Illinois Chicago</publisher>
                 <distributor>TEI-L@UICVM</distributor>
                 <date>1990</date>
                 <relatedItem type="archive">
                   <bibl>
                     <publisher>The Pennsylvania State University</publisher>
                     <distributor>LISTS.PSU.EDU Listserv Server (17.0)</distributor>
                     <date>2024</date>
                   </bibl>
                 </relatedItem>
               </bibl>
             </sourceDesc>
           </fileDesc>
           <encodingDesc>
             <samplingDecl>
               <p>Sampled by requesting monthly logs from <name type="API">LISTS.PSU.EDU</name> by
               email with GET commands: <code>GET TEI-L LOG 9001</code> (for January 1990). One log
               command was issued for each month. See <ptr type="APIdoc"
               target="https://www.lsoft.com/manuals/17.0/commands/14File-serverandwebfunctioncomma.html"/>. 
               Received by email between <date from="2024-09-21" to="2024-09-22">September 21
               and 22, 2024</date>.</p>
             </samplingDecl>
           </encodingDesc>
         </teiHeader>
       </egXML>
       </p>
       <p>In the <gi>text</gi> of the TEI document, we encoded information about the collection of posts and the posts themselves. 
       Since Listserv delivers the logs as files representing an entire month of posts, we supplied a unique identifier to each 
       monthly log collection on <code>text/body/div[@type="log"]/@xml:id</code>. Within this <tag>div type="log"</tag>, we
       encoded each email message inside a <gi>post</gi> element, drawn from the new CMC chapter.</p>
       <p>To store the metadata for individual email messages, in this method we encoded a <gi>dateline</gi> element, which contained
       <gi>ref</gi> elements to store information about the transmission of the message within its parent <gi>post</gi>, thus:
       <table xml:id="field_mapping2">
         <row><cell>Date</cell><cell><code>date/@when</code> or <code>date/text()</code></cell></row>
         <row><cell>Reply-To</cell><cell><code>ref[@type="reply-to"][@target="email:___]</code></cell></row>
         <row><cell>Sender</cell><cell><code>ref[@generatedBy="system"][@type="sender"][@target="email:TEI-L@__]</code></cell></row>
         <row><cell>From</cell><cell><code>ref[@generatedBy="template"][@type="from"][@target="email:___"]</code></cell></row>
         <row><cell>Subject</cell><cell><code>title[@level="a"][@generatedBy="human"]</code></cell></row>
         <row><cell>In-Reply-To</cell><cell><code>ref[@target="#id-of-earlier-posting]</code></cell></row>
       </table>
       Notice that in this encoding we are experimenting with setting
       the Subject field in a <gi>title</gi> element, supplying a
       <att>level</att> with a value of <val>a</val>, which seems
       fitting for a portion of an assembled collection. Here is an
       example encoding of a single email message encoded as a
       <gi>post</gi> following this method:
       <egXML xmlns="http://www.tei-c.org/ns/Examples">
         <post xml:id="Web-1990-01-31-0933">
           <dateline>
             <date when="1990-01-31">Wed, 31 Jan 90 09:33:26 CST</date>
             <ref generatedBy="system" type="reply-to" target="email:TEI-L@UICVM">Text Encoding
             Initative public discussion list </ref>
             <ref generatedBy="system" type="sender" target="email:TEI-L@UICVM">Text Encoding
             Initative public discussion list</ref>
             <ref generatedBy="template" type="from" target="email:WEBER@HARVARDA.BITNET">Robert
             Philip Weber</ref>
             <title level="a" type="subject" generatedBy="human">compound documents and
             images</title>
           </dateline>
           <p>could someone please explain the <name type="ML">TEI</name> approach to compound
           documents and images? WIll <name type="ML">SGML</name> be used here, and if so,
           how? I've just joined the list. sorry if this has been asked before.</p>
           <p>Many Thanks</p>
           <signed generatedBy="human">Bob Weber</signed>
           <signed generatedBy="template"> Robert Philip Weber, Ph.D. | Phone: (617) 495-3744
           <lb/>Senior Consultant | Fax: (617) 495-0750 <lb/>Academic and Planning Services |
           <lb/>Division | <lb/>Office For Information Technology| Internet:
           weber@popvax.harvard.edu <lb/>Harvard University | Bitnet: Weber@Harvarda <lb/>50
           Church Street | <lb/>Cambridge MA 02138 | </signed>
         </post>
       </egXML>
       Note that in this example original lineation is not preserved
       (except in the signature template), but said lineation was used
       as evidence for establishing paragraph boundaries.</p>
     </div>
     <div xml:id="TEI-post">
       <head>One TEI Document for a Single Post</head>
       <p>A collection of posts could conceivably be encoded as a
       collection of TEI documents, sharing the same root of
       <gi>TEI</gi> or <gi>teiCorpus</gi>. For this method, we would
       apply the same outer <gi>teiHeader</gi> as shown in previous
       examples, but then supply metadata about each post in the
       <gi>teiHeader</gi> elements of the internal <gi>TEI</gi>
       elements. This approach treats each email message directed to
       the Listserv more as we would encode written and mailed
       correspondence.</p>
        
        <div xml:id="TEI-post-titleStmt">
          <head>One TEI Document per Post with Subject in Title Statement</head>
          <p>In this example, we supply the email message header information in a <gi>correspDesc</gi> 
            rather than in the <gi>dateline</gi>, and we ventured to
           develop the <code>teiHeader/titleStmt</code> to deliver the subject line of a list message as its <gi>title</gi>, with the writer’s name given
           as the author, and also the person responsible for the <code>correspAction/@type="sent"</code> (usually the same as the writer).      
         <egXML xmlns="http://www.tei-c.org/ns/Examples">
           <TEI>
             <teiHeader>
               <fileDesc>
                 <!-- same as previous example … -->
               </fileDesc>
               <encodingDesc>
                 <!-- same as previous example …  -->
               </encodingDesc>
             </teiHeader>
             <TEI xml:id="Web-1990-01-31-0933">
               <teiHeader>
                 <fileDesc>
                   <titleStmt>
                     <title type="subjectLine">compound documents and images</title>
                     <author>Robert Philip Weber</author>
                   </titleStmt>
                   <publicationStmt>
                     <p>Text Encoding Initative public discussion list</p>
                   </publicationStmt>
                   <sourceDesc>
                     <bibl><title level="s">LOG9001</title></bibl>
                   </sourceDesc>
                 </fileDesc>
                 <profileDesc>
                   <langUsage>
                     <language ident="en">English</language>
                   </langUsage>
                   <correspDesc>
                     <correspAction type="sent">
                       <persName>Robert Philip Weber</persName>
                       <email>WEBER@HARVARDA.BITNET</email>
                       <date when="1990-01-31">Wed, 31 Jan 90 09:33:26 CST</date>
                     </correspAction>
                     <correspAction type="relayed">
                       <orgName><ref target="mailto:TEI-L@UICVM">Text Encoding
                           Initative public discussion list</ref></orgName>
                     </correspAction>            
                   </correspDesc>
                 </profileDesc>
               </teiHeader>
               <text>
                 <body>
                   <post>
                     <p>could someone please explain the <name type="ML">TEI</name> approach to compound
                       documents and images? WIll <name type="ML">SGML</name> be used here, and if so,
                       how? I've just joined the list. sorry if this has been asked before.</p>
                     <p>Many Thanks</p>
                     <signed generatedBy="human">Bob Weber</signed>
                     <signed generatedBy="template"> Robert Philip Weber, Ph.D. | Phone: (617) 495-3744
                       <lb/>Senior Consultant | Fax: (617) 495-0750 <lb/>Academic and Planning Services |
                       <lb/>Division | <lb/>Office For Information Technology| Internet:
                       weber@popvax.harvard.edu <lb/>Harvard University | Bitnet: Weber@Harvarda <lb/>50
                       Church Street | <lb/>Cambridge MA 02138 | </signed>               
                   </post>
                 </body>
               </text>
             </TEI>
             <TEI xml:id="Spe-1990-02-06-1054">
               <teiHeader>
                 <fileDesc>
                   <titleStmt>
                     <title type="subjectLine">compound documents</title>
                     <author>Michael Sperberg-McQueen</author>
                   </titleStmt>
                   <publicationStmt>
                     <p>Text Encoding Initative public discussion list</p>
                   </publicationStmt>
                   <sourceDesc>
                     <bibl><title level="a">LOG9002</title></bibl>
                   </sourceDesc>
                 </fileDesc>
                 <profileDesc>
                   <langUsage>
                     <language ident="en">English</language>
                   </langUsage>
                   <correspDesc>
                     <correspAction type="sent">
                       <persName>Michael Sperberg-McQueen</persName>
                       <email>U35395@UICVM.BITNET</email>
                       <date when="1990-02-06">Tue, 6 Feb 90 10:54:04 CST</date>
                     </correspAction>
                     <correspAction type="relayed">
                       <orgName><ref target="TEI-L@UICVM">Text Encoding
                           Initative public discussion list</ref></orgName>
                     </correspAction>  
                     <correspContext>
                       <ref type="in-response-to" target="#Web-1990-01-31-0933">previous message of 
                         <persName>Robert Philip Weber</persName> to the TEI-L Listserv.
                         <date when="1990-01-31"/>
                       </ref>
                     </correspContext>
                   </correspDesc>
                 </profileDesc>
               </teiHeader>
               <text>
                 <body>
                   <post>
                     <p>About compound documents in <name type="ML">SGML</name> and in the <name type="ML"
                         >TEI</name>. <ref target="#Web-1990-01-31-0933"><persName>R.P. Weber</persName>
                           asked a week ago <q>could someone please explain the <name type="ML">TEI</name>
                             approach to compound documents and images? WIll <name type="ML">SGML</name>
                             be used here, and if so, how?</q></ref></p>
                     <p>Apologies for my delay in answering. I was hoping one of our hypertext sages might
                       weigh in with a reply. (But he appears to have been in the
                       <placeName>Caribbean</placeName>, and may not have received the query.)</p>
                      <!-- 8 paragraphs omitted … -->
                     <p>Perhaps those subscribers to this list who actually work with compound documents
                       and <name type="ML">SGML</name> will be willing to say how they make things work
                       now, and how they would like to see things developing in the future.</p>
                     <p> All this is, I repeat, just personal opinion and shouldn't be taken as defining
                       <soCalled>the</soCalled> position of the <orgName>TEI</orgName>. (Unless, of
                       course, taking as <soCalled>the</soCalled> position will help get a discussion
                       started.)</p>
                     <signed generatedBy="human">-Michael Sperberg-McQueen<lb/> University of Illinois at
                       Chicago </signed>
                   </post>
                 </body>
               </text>
             </TEI>
           </TEI>
         </egXML>
       </p>
     </div>
     <div xml:id="tei-post-xeno">
       <head>One TEI document per Post with Subject in its <gi>head</gi></head>
       <p>In the process of automating the conversion of Listserv data to XML, we prepared a rather different version
       of a <gi>TEI</gi> element that stores a single email message. Like the previous example, each email message is stored in 
       a TEI child of a TEI document, but in this approach, the email message metadata has been stored in different locations:
       <list>
         <item>in a <gi>correspDesc</gi> within the <gi>teiHeader</gi>,</item>
         <item>in the attributes of each <gi>post</gi>,</item>
         <item>in a <gi>head</gi> first child of each <gi>post</gi>,
         and, in addition,</item>
         <item>a copy of the original field values in a <gi>xenoData</gi> within the <gi>teiHeader</gi></item>
       </list>
       
       <egXML xmlns="http://www.tei-c.org/ns/Examples">
         <TEI>
           <teiHeader>
             <fileDesc>
               <titleStmt>
                 <title><!-- basename of input document --></title>
                 <title type="sub">a corpus of 38787 postings</title>
               </titleStmt>
               <publicationStmt>
                 <ab>Currently an experimental document. The original source was
                 published as part of a public mailing list, so this
                 document similarly is publicly available.</ab>
               </publicationStmt>
               <sourceDesc>
                 <ab>Derived from source file /path/to/INPUT.txt, which
                 should be a log file from a Listserv mailing list.</ab>
               </sourceDesc>
             </fileDesc>
             <encodingDesc>
               <appInfo>
                 <application ident="listserv_log2cmc.xslt" version="0.1">
                   This file generated 2025-02-25T14:11:16.933643722-05:00 by file:/path/to/listserv_log2cmc.xslt
                   using /path/to/INPUT.txt as input.
                 </application>
               </appInfo>
             </encodingDesc>
            <particDesc>
              <!-- <listPerson> here, see discussion below … -->
            </particDesc>
           </teiHeader>
           <!-- 4 <TEI> elements missing here … -->
           <TEI n="00005" xmlns:tmp="http://www.wwp.neu.edu/temp/ns"
                xml:id="TEI-L.txt_msg_00005">
             <teiHeader>
               <fileDesc>
                 <titleStmt>
                   <title>TEI-L posting from INPUT.txt, #5</title>
                 </titleStmt>
                 <!-- <publicationStmt> from corpus header repeated here … -->
                 <!-- <sourceDesc> from corpus header essentially repeated here … -->
               </fileDesc>
               <!-- <encodingDesc> from corpus header essentially repeated here … -->
               <profileDesc>
                 <correspDesc>
                   <correspContext>
                     <ptr type="reply-to" target="mailto:TEI-L@UICVM"/>
                   </correspContext>
                   <correspAction type="relayed">
                     <email>TEI-L@UICVM</email>
                     <date>Tue, 6 Feb 90 10:54:04 CST</date>
                   </correspAction>
                   <note type="Comments">"ACH / ACL / ALLC Text Encoding Initiative"</note>
                 </correspDesc>
               </profileDesc>
               <xenoData>
                 <tmp:Date>Tue, 6 Feb 90 10:54:04 CST</tmp:Date>
                 <tmp:Reply-To>Text Encoding Initative public discussion list &lt;TEI-L@UICVM&gt;</tmp:Reply-To>
                 <tmp:Sender>Text Encoding Initative public discussion list &lt;TEI-L@UICVM&gt;</tmp:Sender>
                 <tmp:Comments>"ACH / ACL / ALLC Text Encoding Initiative"</tmp:Comments>
                 <tmp:From>Michael Sperberg-McQueen 312 996-2477 -2981 &lt;U35395@UICVM.BITNET&gt;</tmp:From>
                 <tmp:Subject>compound documents</tmp:Subject>
               </xenoData>
             </teiHeader>
             <text>
               <body>
                 <post who="#u35395·＠·uicvm.bitnet"
                       when="1990-02-06T10:54:04-06:00">
                   <head type="subject">compound documents</head>
                   About compound documents in SGML and in the TEI.  R.P. Weber asked a
                   <lb n="1"/>week ago "could someone please explain the TEI approach to compound
                   <lb n="2"/>documents and images?  WIll SGML be used here, and if so, how?"
                   <lb n="3"/>
                   <lb n="4"/>Apologies for my delay in answering.  I was hoping one of our hypertext
                   <lb n="5"/>sages might weigh in with a reply.  (But he appears to have been in the
                   <lb n="6"/>Caribbean, and may not have received the query.)
                   <!-- 87 lines deleted here to reduce size of example … -->
                   <lb n="88"/>All this is, I repeat, just personal opinion and shouldn't be taken as
                   <lb n="89"/>defining "the" position of the TEI.  (Unless, of course, taking as "the"
                   <lb n="90"/>position will help get a discussion started.)
                   <lb n="91"/>
                   <lb n="92"/>-Michael Sperberg-McQueen
                 <lb n="93"/> University of Illinois at Chicago</post>
               </body>
             </text>
           </TEI>
         </TEI>
       </egXML>
           
           Because this encoding was generated by an (XSLT)
           application, information about that application is stored
           in <gi>appInfo</gi> in the <gi>encodingDesc</gi>. And although
           the metadata expressed in the email header fields is mapped
           to various TEI constructs, a verbatim copy of the value of
           each field is retained (in <gi>xenoData</gi>).<note>The fields
           are currently stored using elements from a temporary
           namespace. We are considering using a namespace
           URI that refers to RFC 5322 (perhaps
           <code>https://datatracker.ietf.org/doc/html/rfc5322</code>), 
           and using a prefix of <code>rfc5322:</code>.</note>
           The values of the field names are used as the local names
           of elements within <gi>xenoData</gi>, but are not used
           verbatim. Since email header fields are case insensitive,
           we have removed case distinctions when translating field
           names to the local names of elements.</p>
           <p>The repetition of metadata in <gi>xenoData</gi> serves
           two purposes. The first (and for now, primary) purpose is
           to make debugging our program easier. But we anticipate
           that reporting the raw data will be useful to those
           researchers who are well versed in XPath and interested in
           details of email communication. For example, determining
           exactly how the <code>From:</code> field was punctuated or
           what capitalization was used for the
           <q>quoted-printable</q> transfer encoding is not otherwise
           possible using the output of our program.</p>
           <p>Similar to our previous encoding,
           the <gi>correspDesc</gi> also stores the distinct
           identifier of the message to which this is a reply.
           Perhaps the most significant difference is moving the information about the sender of the message to the <gi>post</gi> element, where the 
             sender is designated on the <att>who</att> with a distinct identifier, mapped from their email address, and the date and time of initial sending
           supplied on <att>when</att>.</p>
           <p>One field that gave us significant pause is the
           <code>Subject:</code> field. Although such fields are
           ubiquitous in office memos and in email headers, they
           are not a normal part of either physical correspondence or
           the sorts of media CMC encoding was intended for. We have
           experimented with both encoding the subject line as the heading
           of the <gi>post</gi> (using the <gi>head</gi> element) and as the
           <gi>title</gi> in the TEI header. Neither seems entirely
           satisfactory.</p>
           <p>Encoding the <code>Subject:</code> as the heading of the
           <gi>post</gi> results in a a very usable encoding that is
           easy to understand and process. But it leaves us unsettled
           because it implies that the subject information was
           originally part of the email body (as is the rest of the
           content of <gi>post</gi>), which it was not—it was
           metadata, albeit directly associated with the body.</p>
           <p>While encoding the <code>Subject:</code> in the <gi>title</gi>
           inside the <gi>titleStmt</gi> correctly puts it in a metadata
           container, it is not the correct container. This
           <gi>title</gi> is supposed to be the title of the TEI
           encoded file, not of that which is encoded. Besides, we are
           uncomfortable equating a subject and a title.</p>
           <p>One possible future encoding of this information would
           be to store both the title of the TEI document and the
           subject of the encoded email as separate <gi>title</gi>
           elements in the <gi>titleStmt</gi>, differentiated by
           <att>type</att> or nesting. But we have not attempted to
           implement this yet.</p>
           <p>In this example, the human authorship of the message and
           the designation of its subject is entirely designated
           within the <gi>post</gi>, in a manner more like the way CMC
           encoding approaches discussion board or wiki posts, and
           less like the way we would handle the encoding of a letter
           as part of a collection of correspondence. While letters do
           not usually have subject lines, the personal actions of
           transmission and receipt are typically addressed in the
           <gi>teiHeader</gi>, wherein the <gi>titleStmt</gi> often
           provides information about the exchange, and the
           <gi>correspDesc</gi> is used to provide detailed
           information about how messages literally change hands, from
           the writer to the postal agent to the recipient.</p>
       </div>
     </div>
      <div xml:id="emailography">
        <head>Emailography?</head>
        <p>An archive of an email list is likely to, and in our case
        does, contain posts from many members of its community. And
        information about members of the community, particularly about
        historic or inaugural figures, is likely to be of interest to
        the community. Thus it seemed prudent for our XSLT process to
        develop a set of structured information about participants in
        the email exchanges recorded in the source archive. If nothing
        else, TEI CMC encoding of a <gi>post</gi> uses such a
        structure to indicate who is the author of the posting (using
        <att>who</att>, a pointer to the structured information about
        the author of the posting).</p>
        <p>However, the only information about individual participants in the
        Listserv archives that is available in highly structured form
        are their email addresses and names, and even the names are
        sometimes absent. To make matters worse, a name, when
        present, is that which the author’s email client uses, which
        may not be entirely under the author’s control.<note>For
        example, the Northeastern University mail system puts a user’s
        name in the <code>From:</code> field in <q>Surname,
        Forename</q> order.</note></p>
        <p>Other information about posters to the list may be
        available (e.g., from their signatures, or by looking at the
        dates on which they posted), but only names and email
        addresses are readily available in dedicated metadata fields.
        Nonetheless, an automatically generated structured
        <soCalled>’ography</soCalled> of those who post seems like a
        good idea, both as a starting point for those wishing to add
        further information about parties involved, and as a place for
        the <att>who</att> attribute of <gi>post</gi> to point. But
        how should we structure this set information? Eschewing
        complex calculations or heuristics for now, we only have two
        relevant pieces of information about the sender of any given
        piece of email: a name and an email address. And even though
        there is a strict one-to-one relationship between these pieces of
        information <emph>for a particular post</emph>, many people
        post multiple times to the list.</p>
        <p>It is often the case that for a given name multiple email
        addresses were used. For example, the email address
        <email>emcaulay@library.ucla.edu</email> is associated with
        three different names: <q>McAulay, Elizabeth</q>, <q>Elizabeth
        McAulay</q>, and <q>McAulay, Lisa</q>. (It is easy for a human
        to see these are probably the same person. It would be far
        more difficult, although not impossible, for a computer to
        make that inference.) In another case the email address
        <email>gusfer@gmail.com</email> is associated with two
        distinctly different names (for the same person): <q>Gus
        Riva</q> and <q>Gustavo Fern=?UTF-8?Q?=C3=A1ndez_Riva?=</q>
        (which, according to the rules sketched out in <ptr
        type="crossref" target="#quoted-printable"/>, could be
        expressed as <q>Gustavo Fernández Riva</q>).</p>
        <p>Conversely, for any given name, several email addresses may
        have been used in different postings. For example, the name
        <q>C. M. Sperberg-McQueen</q> is associated with
        <email>U35395@UICVM.BITNET</email>,
        <email>U59467@UICVM.BITNET</email>, and
        <email>cmsmcq@acm.org</email>.</p>
        <p>Something like a TEI <soCalled>personography</soCalled>
        data structure (a <gi>listPerson</gi> with a series of
        <gi>person</gi> elements) is called for. Our first attempted program
        actually generates exactly this personography structure, but 
        we are unsatisfied with this encoding. Before discussing why 
        we are unsatisfied with our own encoding, it is worth pointing out 
        the two approaches that can be taken when generating the bare bones personography. 
        Given that the only types of information we have are names and email
        addresses, we could create either a structure of entries
        identified by email address, each of which lists the various
        names associated with that address; or a structure of entries
        identified by name, each of which lists the various email
        addresses associated with that name.</p>
        <p>We chose the former (a structure based on email addresses,
        each of which lists one or more names that are associated with
        it), primarily because it is a lot easier to convert the email
        addresses to XML IDs than it is to convert the names to XML
        IDs. There are only seven characters that occur in our set of
        email addresses that cannot occur in an XML ID: <code>@</code>, 
          <code>:</code>, <code>!</code>, <code>+</code>, <code>%</code>,
        /, and <code>~</code>. Conversely, in the set of names extracted from the
        <code>From:</code> fields of this dataset, there are over a
        dozen characters not allowed in an XML ID including some which
        make manipulating them in XSLT annoying: <code>'</code>, <code>"</code>, and
        <code>&amp;</code>. Others include <code>©</code>, <code>¶</code>, <code>)</code>, 
          <code>(</code>, <code>¡</code>, <code>Ð</code>, and <code>¼</code>.</p>
        <p>So for each unique email address in the <code>From:</code>
        fields of our dataset we generated a <gi>person</gi> element
        that had an <att>xml:id</att> that was generated from the
        given email address, and from which the email address could be
        reproduced.<note>That is, the conversion process from email
        address to XML ID is deliberately round-tripable. We have not,
        however, yet written code to convert an ID back into an email
        address, and likely never will, given that the email address
        is stored elsewhere in the <gi>person</gi> entry.</note>
        Inside that <gi>person</gi> element we list each unique name
        associated with it, and then reproduce the email address.</p>
        <p>We find it dissatisfying that the only way to include an
        <gi>email</gi> inside a <gi>person</gi> is to place it inside
        a <gi>p</gi>, <gi>ab</gi>, or <gi>note</gi> that is itself
        inside the <gi>person</gi>. This feels clumsy to us.
        After all, an email address is a key piece of information
        many of us wish to record about people. That said, the
        correspondence between people and email addresses is not at
        all a simple one, so a simple child relationship may be
        insufficient. Furthermore, email addresses come and go, so at
        the very least <gi>email</gi> would have to be added to the
        <name>att.datable</name> class in order to make it usable as a
        child of <gi>person</gi>. It might be reasonable instead to
        make <gi>email</gi> a child of <gi>state</gi> (which, in turn,
        is available as a child of <gi>person</gi> and a member of
        att.datable and att.typed).</p>
        <p>We can imagine further processing that might enhance this
        data. For example, a routine could check to see the
        chronologically earliest and latest use of each name and
        record that information. It might be reasonable to look for
        each name in <emph>other</emph> entries and generate links
        between entries that contain the same name. One might group
        entries by the email address domain name. For each entry,
        minimum, average, and maximum lengths of posts might be
        included. (Although it is an interesting question which MIME
        part one uses to calculate length, and how the calculation is
        performed.)</p>
        <p>So while we are not entirely satisfied with our current
        <soCalled>personography</soCalled> structure, we are not entirely
        <emph>dissatisfied</emph> with it, either. But either way, we
        are uncomfortable with our data structure in principle, because it is <emph>not
          really a personography</emph>. It is not a set of data structures
        about people, but rather it is a set of data structures about email
        addresses. We could, of course, use generic structures instead
        of abusing the special purpose elements. An example follows.
        <?jtei Note to JTEI editors: the FULLWIDTH COMMERCIAL AT
          (U+FF20) used in the @xml:id below is not surviving FOP
          processing. Unless you have any magic up your sleeve, we
          will have to search for another character to use, here. ?>
        <egXML xmlns="http://www.tei-c.org/ns/Examples">
          <list type="emailography">
            <item xml:id="nsmith·＠·email.unc.edu">
              <name>Natalia Smith</name>
              <name>Natasha Smith</name>
              <email>nsmith@email.unc.edu</email>
            </item>
            <!-- hundreds of other <item>s here -->
          </list>
        </egXML>
        Note the use of the character sequence <code>·＠·</code>
        (MIDDLE DOT, FULLWIDTH COMMERCIAL AT, MIDDLE DOT; U+00B7,
        U+FF20, U+00B7) instead of just <q>@</q> (COMMERCIAL AT;
        U+0040). This is because an <q>@</q> is not permitted in
        an XML Name, but <q>·</q> and <q>＠</q> are, per <ref type="bibl"
        target="#XML">XML</ref>.</p>
        <p>While a generic representation is possible, an emailography
        might be better encoded with the proposed <gi>listEntity</gi>
        element as discussed on <ref
        target="https://github.com/TEIC/TEI/issues/2341">TEI issue
        #2341</ref>. An <gi>entity</gi> is more precise than a generic
        <gi>item</gi>, and could be (depending on the definition used
        for <gi>entity</gi>) far more applicable than
        <gi>person</gi>. In any case, the limited locations permitting
        the already established <gi>email</gi> element seem
        short-sighted as the TEI contemplates the archiving of
        born-digital texts.</p> 
      </div>
   </div>
   <div xml:id="improving-tei">
     <head>Conclusion: Improving the TEI for the Encoding of Born-digital Resources?</head>
     <p>This paper has explored several challenges and possibilities for the TEI to encounter the born-digital resource of the email list,
     and presented quite a few potentially interesting statistics along the way. Since the digital text is so ephemeral and contingent, 
     yet so full of information about the computer age, our methods in archiving such work should 
      help to sustain it as a resource for scholarly research, rescuing it from loss from changes in technology providers that take little care for 
      maintaining access to or preserving heritage. In our specific efforts to archive Listserv data, we find that 
      the TEI can benefit from some improvements.</p>
     <p>The limited valid positions for <gi>email</gi> in TEI documents are a concern as we begin to develop emailographies, and also as we need to 
       reference email addresses as primary resource of information in born-digital documents. That <gi>email</gi> cannot be a child of <gi>person</gi>
       (or the basis for its own list) raised problems for us. More robust encoding should be developed.</p>
     <p>The <gi>post</gi> element, as a descendant of <gi>text</gi>, contains <soCalled>normal</soCalled> transcriptional elements for
     encoding the logical structure of a document. But given that at its core an email message is definitionally a series of
     characters, and (because indication of line breaks is well defined) they can easily be considered as a sequence of lines, in
     some situations it makes sense to use an embedded transcription approach. <cit><quote source="#PHZLAB">An <term>embedded
     transcription</term> is one in which <supplied>the characters</supplied> <gap/> are encoded as subcomponents of elements representing the physical surfaces carrying them rather
     than independently of them.</quote><ref type="bibl" xml:id="PHZLAB" target="#P5">P5 § 12.2.2</ref></cit> In TEI this
     approach makes use of <gi>line</gi> elements within a <gi>sourceDoc</gi>. However, in the case of an email message,
     there are no physical surfaces, so the intermediate elements (<gi>surfaceGrp</gi>, <gi>surface</gi>, and <gi>zone</gi>) do not
     seem applicable. So while <gi>line</gi> within <gi>sourceDoc</gi> may not be the right mechanism, some method for representing
     email as a relatively uninterpreted sequence of lines of characters should be available; or at the very least, we need to
     be able to preserve the ASCII art of yesteryear.</p>
     <p>The TEI provides no good way to encode an email Subject line in either <gi>correspDesc</gi> or <gi>dateline</gi>, and our 
       attempts to place the Subject varied a little too widely. We do not find the use of the <gi>head</gi> element in <gi>post</gi> 
       satisfactory to encode an email Subject because it is not really part of the email body, but part of the heading metadata stored with From, To,
       CC, etc. Setting it in the <gi>titleStmt</gi> certainly presents the Subject line as metadata, but it is then metadata about the encoded
       TEI document, not necessarily the source. This could be overcome by consistent use of a system that included the latter in the former.
       (E.g., if each <gi>TEI</gi> that represented a posting to the list had a <gi>title</gi> of <code>A TEI encoding of TEI-L post #04570
             of &lt;date when="2002-11-04T11:54:15">Mon, 4 Nov 2002&lt;/date> by &lt;persName>Seal, Jill&lt;/persName>
             with subject &lt;title level="a" type="subject">Re: multiple page range in master&lt;/title></code>. Verbose, but it works.)</p>
     <p>Contemplating the use of the <gi>title</gi> element raises questions about the available values for <att>level</att>. What <att>level</att> 
       values are appropriate for the <gi>title</gi> of the TEI-L Listserv as a whole, for the log files it curates by the month, or 
       for the individual email message if we use a <gi>title</gi> element to store its Subject line? Perhaps we could apply a 
       <att>level</att> of <val>s</val> (for series) for the title of the collected
       archives of a Listserv mailing list, a <att>level</att> of <val>m</val> (for monographic) for the title
       of a single monthly log file, and a <att>level</att> of <val>a</val> (for analytic) for the title of a single post to the list. But monographic, 
       usually associated with bound books or works concentrating purposefully on a single topic, does not seem 
       at all appropriate for a log file of posts sent conversationally to an email Listserv. Perhaps <att>level</att> of <val>j</val> would be marginally more appropriate
       for the log files, but they do not bear much resemblance to journal or magazine publications with planned contents. Do we need new values of <att>level</att> for born-digital compound artifacts?
       </p>
     <p>Identifying these issues is the first step to introducing new encoding models. We hope that our work in progress provides a basis for further discussion,
     debate over our experimental data modeling of the TEI Listserv, one of our oldest and most important resources in the TEI community.</p>
      </div>
 </body>
 <back> 
   <div type="bibliography">
     <listBibl>
       <bibl xml:id="EXPath">
         Kosek, Jirka and Lumley, John, <title level="m">Binary Module
         1.0</title> EXPath Module 3, December 2013; <idno
         type="URL">https://expath.org/spec/binary</idno>.
       </bibl>
       <bibl xml:id="RFC2045">
         Freed, N. and Borenstein N., Eds., <title
         level="m">Multipurpose Internet Mail Extensions (MIME) Part
         One: Format of Internet Message Bodies</title>, RFC 2045,
         November 1996; <idno type="DOI">10.17487/RFC2045</idno>.
       </bibl>
       <bibl xml:id="RFC2047">
         Moore, K., Ed., <title level="m"> MIME (Multipurpose Internet
         Mail Extensions) Part Three: Message Header Extensions for
         Non-ASCII Text</title>, RFC 2822, April 2001; <idno
         type="DOI">10.17487/RFC2047</idno>.
       </bibl>
       <bibl xml:id="RFC2822">
         Resnick, P., Ed., <title level="m">Internet Message
         Format</title>, RFC 2822, April 2001;
         <idno type="DOI">10.17487/RFC2822</idno>.
       </bibl>
       <bibl xml:id="RFC5322">
         Resnick, P., Ed., <title level="m">Internet Message
         Format</title>, RFC 5322, October 2008;
         <idno type="DOI">10.17487/RFC5322</idno>.
       </bibl>
       <bibl xml:id="P5">
         TEI Consortium, eds. <title level="m">TEI P5: Guidelines for
         Electronic Text Encoding and
         Interchange</title>. 4.9.0. 2025-01-24. TEI
         Consortium. https://www.tei-c.org/Vault/P5/4.9.0/doc/tei-p5-doc/en/html/index.html
         2025-03-02.
       </bibl>
       <bibl xml:id="XML">
         Bray, Tim; Paoli, Jean; Sperberg-McQueen, C. M.; Maler,
         Eve; and Yergeau, François; Eds., <title
         level="m">Extensible Markup Language (XML) 1.0 (Fifth
         Edition)</title>, November 2008;
         <ptr target="https://www.w3.org/TR/REC-xml/"/>.
       </bibl>
     </listBibl>
   </div>
   <div type="appendix" xml:id="appendix01">
     <?jtei Note to JTEI editors: for an idea of what this might look like see
       https://tei-cmc-experiment.github.io/tei-cmc-experiment/ASCII_not_in_XML.html ?>
     <head>The 29 7-bit ASCII Characters that are not Legal in XML</head>
     <table xml:id="illegal_ascii_chars">
       <row role="label">
         <cell>base 10</cell>
         <cell>base 16</cell>
         <cell>base 02</cell>
         <cell>symbol</cell>
         <cell>description</cell>
       </row>
       <row> <cell>0</cell> <cell>00</cell> <cell>0 000 000</cell> <cell>NUL</cell> <cell>Null character</cell> </row>
       <row> <cell>1</cell> <cell>01</cell> <cell>0 000 001</cell> <cell>SOH</cell> <cell>Start of Heading</cell> </row>
       <row> <cell>2</cell> <cell>02</cell> <cell>0 000 010</cell> <cell>STX</cell> <cell>Start of Text</cell> </row>
       <row> <cell>3</cell> <cell>03</cell> <cell>0 000 011</cell> <cell>ETX</cell> <cell>End of Text</cell> </row>
       <row> <cell>4</cell> <cell>04</cell> <cell>0 000 100</cell> <cell>EOT</cell> <cell>End of Transmission</cell> </row>
       <row> <cell>5</cell> <cell>05</cell> <cell>0 000 101</cell> <cell>ENQ</cell> <cell>Enquiry</cell> </row>
       <row> <cell>6</cell> <cell>06</cell> <cell>0 000 110</cell> <cell>ACK</cell> <cell>Acknowledge</cell> </row>
       <row> <cell>7</cell> <cell>07</cell> <cell>0 000 111</cell> <cell>BEL</cell> <cell>Bell, Alert</cell> </row>
       <row> <cell>8</cell> <cell>08</cell> <cell>0 001 000</cell> <cell>BS</cell> <cell>Backspace</cell> </row>
       <row> <cell>11</cell> <cell>0B</cell> <cell>0 001 011</cell> <cell>VT</cell> <cell>Vertical Tabulation</cell> </row>
       <row> <cell>12</cell> <cell>0C</cell> <cell>0 001 100</cell> <cell>FF</cell> <cell>Form Feed</cell> </row>
       <row> <cell>14</cell> <cell>0E</cell> <cell>0 001 110</cell> <cell>SO</cell> <cell>Shift Out</cell> </row>
       <row> <cell>15</cell> <cell>0F</cell> <cell>0 001 111</cell> <cell>SI</cell> <cell>Shift In</cell> </row>
       <row> <cell>16</cell> <cell>10</cell> <cell>0 010 000</cell> <cell>DLE</cell> <cell>Data Link Escape</cell> </row>
       <row> <cell>17</cell> <cell>11</cell> <cell>0 010 001</cell> <cell>DC1</cell> <cell>Device Control One (XON)</cell> </row>
       <row> <cell>18</cell> <cell>12</cell> <cell>0 010 010</cell> <cell>DC2</cell> <cell>Device Control Two</cell> </row>
       <row> <cell>19</cell> <cell>13</cell> <cell>0 010 011</cell> <cell>DC3</cell> <cell>Device Control Three (XOFF)</cell> </row>
       <row> <cell>20</cell> <cell>14</cell> <cell>0 010 100</cell> <cell>DC4</cell> <cell>Device Control Four</cell> </row>
       <row> <cell>21</cell> <cell>15</cell> <cell>0 010 101</cell> <cell>NAK</cell> <cell>Negative Acknowledge</cell> </row>
       <row> <cell>22</cell> <cell>16</cell> <cell>0 010 110</cell> <cell>SYN</cell> <cell>Synchronous Idle</cell> </row>
       <row> <cell>23</cell> <cell>17</cell> <cell>0 010 111</cell> <cell>ETB</cell> <cell>End of Transmission Block</cell> </row>
       <row> <cell>24</cell> <cell>18</cell> <cell>0 011 000</cell> <cell>CAN</cell> <cell>Cancel</cell> </row>
       <row> <cell>25</cell> <cell>19</cell> <cell>0 011 001</cell> <cell>EM</cell> <cell>End of medium</cell> </row>
       <row> <cell>26</cell> <cell>1A</cell> <cell>0 011 010</cell> <cell>SUB</cell> <cell>Substitute</cell> </row>
       <row> <cell>27</cell> <cell>1B</cell> <cell>0 011 011</cell> <cell>ESC</cell> <cell>Escape</cell> </row>
       <row> <cell>28</cell> <cell>1C</cell> <cell>0 011 100</cell> <cell>FS</cell> <cell>File Separator</cell> </row>
       <row> <cell>29</cell> <cell>1D</cell> <cell>0 011 101</cell> <cell>GS</cell> <cell>Group Separator</cell> </row>
       <row> <cell>30</cell> <cell>1E</cell> <cell>0 011 110</cell> <cell>RS</cell> <cell>Record Separator</cell> </row>
       <row> <cell>31</cell> <cell>1F</cell> <cell>0 011 111</cell> <cell>US</cell> <cell>Unit Separator</cell> </row>
     </table>
     <list type="gloss">
       <head>Regular Expressions to Match these Characters</head>
       <label>PCRE, Java, or oXygen:</label>
       <item><code>[\u0000-\u0008\u000C\u000E-\u0019]</code></item>
       <label>W3C:</label>
       <item><code>[#x00-#x08#x0C#x0E-#x19]</code></item>
       <label>Emacs:</label>
       <?jtei Note to JTEI editors: another character that does not
         survive FOP translation is used in next line. ?>
       <item><code>[^␤[:print:]]</code> &#xA0; &#xA0; &lt;!-- where <q>␤</q> is typed CTL-J --></item>
       <label>grep or egrep:</label>
       <item><code>[^[:print:]]</code></item>
     </list>
   </div>
   <div type="appendix" xml:id="appendix02">
     <head>Date Format Frequency Chart</head>
     <p>See below the chart for a glossary of the format components.</p>
     <table xml:id="dateFormats">
       <row role="label">
         <cell># occurrences</cell>
         <cell>format</cell>
       </row>
       <?jtei Note to JTEI editors: this will be much more readable if
              the 2nd <cell> in each <row> be displayed in a fixed-width
              typeface. ?>
       <row> <cell>32632</cell> <cell>Day, #D Mon YYYY HH:MM:SS ±HHMM</cell> </row>
       <row> <cell>3136</cell> <cell>Day, #D Month YYYY HH:MM:SS ±HHMM</cell> </row>
       <row> <cell>2347</cell> <cell>Day, #D Mon YYYY HH:MM:SS TZA</cell> </row>
       <row> <cell>281</cell> <cell>Day, #D Mon YY HH:MM:SS TZA</cell> </row>
       <row> <cell>245</cell> <cell>Day, #D Month YYYY HH:MM:SS TZA</cell> </row>
       <row> <cell>73</cell> <cell>Day, #D Mon YY HH:MM:SS ±HHMM</cell> </row>
       <row> <cell>22</cell> <cell>Day, #D Mon YY HH:MM:SS LCL</cell> </row>
       <row> <cell>20</cell> <cell>Day, #D Month YY HH:MM:SS LCL</cell> </row>
       <row> <cell>8</cell> <cell>Day, #D Mon YYYY HH:MM:SS LCL</cell> </row>
       <row> <cell>7</cell> <cell>Day, #D Month YY HH:MM:SS TZA</cell> </row>
       <row> <cell>3</cell> <cell>Day, #D Mon YY HH:MM:SS bst</cell> </row>
       <row> <cell>2</cell> <cell>Day, #D Mon YY HH:MM:SS MSZ</cell> </row>
       <row> <cell>2</cell> <cell>Day, #D Mon YY HH:MM:SS TZA</cell> </row>
       <row> <cell>2</cell> <cell>Day, #D Mon YYYY HH:MM:SS MSZ</cell> </row>
       <row> <cell>1</cell> <cell>Day, #D Mon YY HH:MM:SS pst</cell> </row>
       <row> <cell>1</cell> <cell>Day, #D Mon YYYY HH:MM:SS 0000</cell> </row>
       <row> <cell>1</cell> <cell>Day, #D Mon YYYY HH:MM:SS GMT0BST</cell> </row>
       <row> <cell>1</cell> <cell>Day, #D Mon YYYY HH:MM:SS METDST</cell> </row>
       <row> <cell>1</cell> <cell>Day, #D Mon YYYY HH:MM:SS TZONE</cell> </row>
       <row> <cell>1</cell> <cell>Day, #D Month YY HH:MM:SS METDST</cell> </row>
       <row> <cell>1</cell> <cell>Day, #D Month YY HH:MM:SS ±HHMM</cell> </row>
     </table>
     <p>Where:
     <list type="gloss">
       <label>Day</label> <item>Weekday name expressed as 3 letters, capitalized (e.g., <q>Sun</q>.)</item>
       <label>#D</label> <item>One or two digit day-of-the month (e.g., <q>4</q> or <q>26</q>.)</item>
       <label>Month</label> <item>The full month name (e.g., <q>August</q>.)</item>
       <label>Mon</label> <item>The month in 3 letters (e.g., <q>Aug</q>.)</item>
       <label>YYYY</label> <item>A 4-digit year.</item>
       <label>YY</label> <item>A 2-digit year.</item>
       <label>HH</label> <item>A 2-digit hour.</item>
       <label>MM</label> <item>A 2-digit minute.</item>
       <label>SS</label> <item>A 2-digit second.</item>
       <label>±</label> <item>Either <q>+</q> or <q>-</q>.</item>
       <label>TZA</label> <item>A valid time zone symbol.</item>
       <label>Anything else as last token</label> <item>An invalid
       time zone symbol.</item> </list> </p> </div> </back> </text>
       </TEI>
